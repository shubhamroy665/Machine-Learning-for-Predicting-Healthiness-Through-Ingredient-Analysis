{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6650/1664553110.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy(kcal)_per 100 g</th>\n",
       "      <th>Protein(g) per 100 g</th>\n",
       "      <th>Carbohydrate(g) per 100 g</th>\n",
       "      <th>total sugar(g) per 100 g</th>\n",
       "      <th>Added  Sugar(g) per 100 g</th>\n",
       "      <th>fibre(g) per 100 g</th>\n",
       "      <th>total fat (g) per 100 gms</th>\n",
       "      <th>saturated fat (g) per 100 g</th>\n",
       "      <th>trans fat (g) _per 100 g</th>\n",
       "      <th>Sodium(mg) per 100 g</th>\n",
       "      <th>iron (mg) per 100 gm</th>\n",
       "      <th>Cholesterol per 100 mg</th>\n",
       "      <th>Health_Label_High_Cholesterol</th>\n",
       "      <th>Health_Label_High_sugar</th>\n",
       "      <th>Health_Label_for_normal_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>717.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.11</td>\n",
       "      <td>51.368000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>2.870000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.30</td>\n",
       "      <td>45.390000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>876.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.48</td>\n",
       "      <td>61.924000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>353.000000</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>2.340000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.74</td>\n",
       "      <td>18.669000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1146.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371.000000</td>\n",
       "      <td>23.240000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.68</td>\n",
       "      <td>18.764000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28103</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053120</td>\n",
       "      <td>0.179173</td>\n",
       "      <td>0.017707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.114663</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28104</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.157546</td>\n",
       "      <td>51.157546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.787729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28105</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.498168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28106</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015285</td>\n",
       "      <td>0.277072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.127376</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28107</th>\n",
       "      <td>283.652188</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>76.738000</td>\n",
       "      <td>76.396072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023063</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.230625</td>\n",
       "      <td>0.074972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28108 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Energy(kcal)_per 100 g  Protein(g) per 100 g  \\\n",
       "0                  717.000000              0.850000   \n",
       "1                  718.000000              0.490000   \n",
       "2                  876.000000              0.280000   \n",
       "3                  353.000000             21.400000   \n",
       "4                  371.000000             23.240000   \n",
       "...                       ...                   ...   \n",
       "28103                1.000000              0.053120   \n",
       "28104              190.000000              0.000000   \n",
       "28105                0.000000              0.000000   \n",
       "28106                1.000000              0.015285   \n",
       "28107              283.652188              0.034594   \n",
       "\n",
       "       Carbohydrate(g) per 100 g  total sugar(g) per 100 g  \\\n",
       "0                       0.060000                  0.060000   \n",
       "1                       2.870000                  0.060000   \n",
       "2                       0.000000                  0.000000   \n",
       "3                       2.340000                  0.500000   \n",
       "4                       2.790000                  0.510000   \n",
       "...                          ...                       ...   \n",
       "28103                   0.179173                  0.017707   \n",
       "28104                  51.157546                 51.157546   \n",
       "28105                   0.000000                  0.000000   \n",
       "28106                   0.277072                  0.000000   \n",
       "28107                  76.738000                 76.396072   \n",
       "\n",
       "       Added  Sugar(g) per 100 g  fibre(g) per 100 g  \\\n",
       "0                            0.0            0.000000   \n",
       "1                            0.0            0.000000   \n",
       "2                            0.0            0.000000   \n",
       "3                            0.0            0.000000   \n",
       "4                            0.0            0.000000   \n",
       "...                          ...                 ...   \n",
       "28103                        0.0            0.000000   \n",
       "28104                        0.0            0.000000   \n",
       "28105                        0.0            0.000000   \n",
       "28106                        0.0            0.000000   \n",
       "28107                        0.0            0.023063   \n",
       "\n",
       "       total fat (g) per 100 gms  saturated fat (g) per 100 g  \\\n",
       "0                          81.11                    51.368000   \n",
       "1                          78.30                    45.390000   \n",
       "2                          99.48                    61.924000   \n",
       "3                          28.74                    18.669000   \n",
       "4                          29.68                    18.764000   \n",
       "...                          ...                          ...   \n",
       "28103                       0.00                     0.000000   \n",
       "28104                       0.00                     0.000000   \n",
       "28105                       0.00                     0.000000   \n",
       "28106                       0.00                     0.001745   \n",
       "28107                       0.00                     0.000000   \n",
       "\n",
       "       trans fat (g) _per 100 g  Sodium(mg) per 100 g  iron (mg) per 100 gm  \\\n",
       "0                           0.0            643.000000              0.020000   \n",
       "1                           0.0            583.000000              0.050000   \n",
       "2                           0.0              2.000000              0.000000   \n",
       "3                           0.0           1146.000000              0.310000   \n",
       "4                           0.0            560.000000              0.430000   \n",
       "...                         ...                   ...                   ...   \n",
       "28103                       0.0              4.114663              0.008853   \n",
       "28104                       0.0             55.787729              0.000000   \n",
       "28105                       0.0              4.498168              0.000000   \n",
       "28106                       0.0              3.127376              0.020000   \n",
       "28107                       0.0              2.230625              0.074972   \n",
       "\n",
       "       Cholesterol per 100 mg  Health_Label_High_Cholesterol  \\\n",
       "0                       215.0                              1   \n",
       "1                       225.0                              1   \n",
       "2                       256.0                              1   \n",
       "3                        75.0                              1   \n",
       "4                        94.0                              1   \n",
       "...                       ...                            ...   \n",
       "28103                     0.0                              0   \n",
       "28104                     0.0                              0   \n",
       "28105                     0.0                              0   \n",
       "28106                     0.0                              0   \n",
       "28107                     0.0                              0   \n",
       "\n",
       "       Health_Label_High_sugar  Health_Label_for_normal_person  \n",
       "0                            0                               1  \n",
       "1                            0                               1  \n",
       "2                            0                               1  \n",
       "3                            0                               1  \n",
       "4                            0                               1  \n",
       "...                        ...                             ...  \n",
       "28103                        0                               0  \n",
       "28104                        0                               0  \n",
       "28105                        0                               0  \n",
       "28106                        0                               0  \n",
       "28107                        0                               0  \n",
       "\n",
       "[28108 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "p=pd.read_csv('cleaned_data3.csv')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy(kcal)_per 100 g</th>\n",
       "      <th>Protein(g) per 100 g</th>\n",
       "      <th>Carbohydrate(g) per 100 g</th>\n",
       "      <th>total sugar(g) per 100 g</th>\n",
       "      <th>Added  Sugar(g) per 100 g</th>\n",
       "      <th>fibre(g) per 100 g</th>\n",
       "      <th>total fat (g) per 100 gms</th>\n",
       "      <th>saturated fat (g) per 100 g</th>\n",
       "      <th>trans fat (g) _per 100 g</th>\n",
       "      <th>Sodium(mg) per 100 g</th>\n",
       "      <th>iron (mg) per 100 gm</th>\n",
       "      <th>Cholesterol per 100 mg</th>\n",
       "      <th>Health_Label_High_Cholesterol</th>\n",
       "      <th>Health_Label_High_sugar</th>\n",
       "      <th>Health_Label_for_normal_person</th>\n",
       "      <th>Health_Label_High_fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>717.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.11</td>\n",
       "      <td>51.368000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>2.870000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.30</td>\n",
       "      <td>45.390000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>876.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.48</td>\n",
       "      <td>61.924000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>353.000000</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>2.340000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.74</td>\n",
       "      <td>18.669000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1146.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371.000000</td>\n",
       "      <td>23.240000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.68</td>\n",
       "      <td>18.764000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28103</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053120</td>\n",
       "      <td>0.179173</td>\n",
       "      <td>0.017707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.114663</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28104</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.157546</td>\n",
       "      <td>51.157546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.787729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28105</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.498168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28106</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015285</td>\n",
       "      <td>0.277072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.127376</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28107</th>\n",
       "      <td>283.652188</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>76.738000</td>\n",
       "      <td>76.396072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023063</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.230625</td>\n",
       "      <td>0.074972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28108 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Energy(kcal)_per 100 g  Protein(g) per 100 g  \\\n",
       "0                  717.000000              0.850000   \n",
       "1                  718.000000              0.490000   \n",
       "2                  876.000000              0.280000   \n",
       "3                  353.000000             21.400000   \n",
       "4                  371.000000             23.240000   \n",
       "...                       ...                   ...   \n",
       "28103                1.000000              0.053120   \n",
       "28104              190.000000              0.000000   \n",
       "28105                0.000000              0.000000   \n",
       "28106                1.000000              0.015285   \n",
       "28107              283.652188              0.034594   \n",
       "\n",
       "       Carbohydrate(g) per 100 g  total sugar(g) per 100 g  \\\n",
       "0                       0.060000                  0.060000   \n",
       "1                       2.870000                  0.060000   \n",
       "2                       0.000000                  0.000000   \n",
       "3                       2.340000                  0.500000   \n",
       "4                       2.790000                  0.510000   \n",
       "...                          ...                       ...   \n",
       "28103                   0.179173                  0.017707   \n",
       "28104                  51.157546                 51.157546   \n",
       "28105                   0.000000                  0.000000   \n",
       "28106                   0.277072                  0.000000   \n",
       "28107                  76.738000                 76.396072   \n",
       "\n",
       "       Added  Sugar(g) per 100 g  fibre(g) per 100 g  \\\n",
       "0                            0.0            0.000000   \n",
       "1                            0.0            0.000000   \n",
       "2                            0.0            0.000000   \n",
       "3                            0.0            0.000000   \n",
       "4                            0.0            0.000000   \n",
       "...                          ...                 ...   \n",
       "28103                        0.0            0.000000   \n",
       "28104                        0.0            0.000000   \n",
       "28105                        0.0            0.000000   \n",
       "28106                        0.0            0.000000   \n",
       "28107                        0.0            0.023063   \n",
       "\n",
       "       total fat (g) per 100 gms  saturated fat (g) per 100 g  \\\n",
       "0                          81.11                    51.368000   \n",
       "1                          78.30                    45.390000   \n",
       "2                          99.48                    61.924000   \n",
       "3                          28.74                    18.669000   \n",
       "4                          29.68                    18.764000   \n",
       "...                          ...                          ...   \n",
       "28103                       0.00                     0.000000   \n",
       "28104                       0.00                     0.000000   \n",
       "28105                       0.00                     0.000000   \n",
       "28106                       0.00                     0.001745   \n",
       "28107                       0.00                     0.000000   \n",
       "\n",
       "       trans fat (g) _per 100 g  Sodium(mg) per 100 g  iron (mg) per 100 gm  \\\n",
       "0                           0.0            643.000000              0.020000   \n",
       "1                           0.0            583.000000              0.050000   \n",
       "2                           0.0              2.000000              0.000000   \n",
       "3                           0.0           1146.000000              0.310000   \n",
       "4                           0.0            560.000000              0.430000   \n",
       "...                         ...                   ...                   ...   \n",
       "28103                       0.0              4.114663              0.008853   \n",
       "28104                       0.0             55.787729              0.000000   \n",
       "28105                       0.0              4.498168              0.000000   \n",
       "28106                       0.0              3.127376              0.020000   \n",
       "28107                       0.0              2.230625              0.074972   \n",
       "\n",
       "       Cholesterol per 100 mg  Health_Label_High_Cholesterol  \\\n",
       "0                       215.0                              1   \n",
       "1                       225.0                              1   \n",
       "2                       256.0                              1   \n",
       "3                        75.0                              1   \n",
       "4                        94.0                              1   \n",
       "...                       ...                            ...   \n",
       "28103                     0.0                              0   \n",
       "28104                     0.0                              0   \n",
       "28105                     0.0                              0   \n",
       "28106                     0.0                              0   \n",
       "28107                     0.0                              0   \n",
       "\n",
       "       Health_Label_High_sugar  Health_Label_for_normal_person  \\\n",
       "0                            0                               1   \n",
       "1                            0                               1   \n",
       "2                            0                               1   \n",
       "3                            0                               1   \n",
       "4                            0                               1   \n",
       "...                        ...                             ...   \n",
       "28103                        0                               0   \n",
       "28104                        0                               0   \n",
       "28105                        0                               0   \n",
       "28106                        0                               0   \n",
       "28107                        0                               0   \n",
       "\n",
       "      Health_Label_High_fat  \n",
       "0                 Unhealthy  \n",
       "1                 Unhealthy  \n",
       "2                 Unhealthy  \n",
       "3                 Unhealthy  \n",
       "4                 Unhealthy  \n",
       "...                     ...  \n",
       "28103               Healthy  \n",
       "28104               Healthy  \n",
       "28105               Healthy  \n",
       "28106               Healthy  \n",
       "28107               Healthy  \n",
       "\n",
       "[28108 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = {\n",
    "    'Energy(kcal)_per 100 g': 400,\n",
    "    'Protein(g) per 100 g': 10,\n",
    "    'Carbohydrate(g) per 100 g': 50,\n",
    "    'total sugar(g) per 100 g': 20,\n",
    "    'Added  Sugar(g) per 100 g': 8,\n",
    "    'trans fat (g) _per 100 g': 5,\n",
    "    'Sodium(mg) per 100 g': 400,\n",
    "    'iron (mg) per 100 gm': 2, 'Cholesterol per 100 mg': 20\n",
    "}\n",
    "\n",
    "def label_health_high_fat(row):\n",
    "    # Check if Cholesterol per 100 mg is 0\n",
    "    # Calculate healthy and unhealthy counts based on other thresholds\n",
    "    healthy_count = sum(row[col] <= threshold for col, threshold in thresholds.items())\n",
    "    unhealthy_count = sum(row[col] > threshold for col, threshold in thresholds.items())\n",
    "    if row['total fat (g) per 100 gms'] == 0:\n",
    "        if healthy_count > unhealthy_count:\n",
    "            return 'Healthy'\n",
    "    else:\n",
    "        return \"Unhealthy\"\n",
    "\n",
    "    \n",
    "\n",
    "# Apply the function to each row in the DataFrame to label the foods\n",
    "p['Health_Label_High_fat'] = p.apply(label_health_high_fat, axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6650/2630207962.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  p[['Health_Label_High_fat']] = p[['Health_Label_High_fat']].replace({'Healthy': 0, 'Unhealthy': 1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy(kcal)_per 100 g</th>\n",
       "      <th>Protein(g) per 100 g</th>\n",
       "      <th>Carbohydrate(g) per 100 g</th>\n",
       "      <th>total sugar(g) per 100 g</th>\n",
       "      <th>Added  Sugar(g) per 100 g</th>\n",
       "      <th>fibre(g) per 100 g</th>\n",
       "      <th>total fat (g) per 100 gms</th>\n",
       "      <th>saturated fat (g) per 100 g</th>\n",
       "      <th>trans fat (g) _per 100 g</th>\n",
       "      <th>Sodium(mg) per 100 g</th>\n",
       "      <th>iron (mg) per 100 gm</th>\n",
       "      <th>Cholesterol per 100 mg</th>\n",
       "      <th>Health_Label_High_Cholesterol</th>\n",
       "      <th>Health_Label_High_sugar</th>\n",
       "      <th>Health_Label_for_normal_person</th>\n",
       "      <th>Health_Label_High_fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>717.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.11</td>\n",
       "      <td>51.368000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>2.870000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.30</td>\n",
       "      <td>45.390000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>876.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.48</td>\n",
       "      <td>61.924000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>353.000000</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>2.340000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.74</td>\n",
       "      <td>18.669000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1146.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371.000000</td>\n",
       "      <td>23.240000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.68</td>\n",
       "      <td>18.764000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28103</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053120</td>\n",
       "      <td>0.179173</td>\n",
       "      <td>0.017707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.114663</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28104</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.157546</td>\n",
       "      <td>51.157546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.787729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28105</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.498168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28106</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015285</td>\n",
       "      <td>0.277072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.127376</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28107</th>\n",
       "      <td>283.652188</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>76.738000</td>\n",
       "      <td>76.396072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023063</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.230625</td>\n",
       "      <td>0.074972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28108 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Energy(kcal)_per 100 g  Protein(g) per 100 g  \\\n",
       "0                  717.000000              0.850000   \n",
       "1                  718.000000              0.490000   \n",
       "2                  876.000000              0.280000   \n",
       "3                  353.000000             21.400000   \n",
       "4                  371.000000             23.240000   \n",
       "...                       ...                   ...   \n",
       "28103                1.000000              0.053120   \n",
       "28104              190.000000              0.000000   \n",
       "28105                0.000000              0.000000   \n",
       "28106                1.000000              0.015285   \n",
       "28107              283.652188              0.034594   \n",
       "\n",
       "       Carbohydrate(g) per 100 g  total sugar(g) per 100 g  \\\n",
       "0                       0.060000                  0.060000   \n",
       "1                       2.870000                  0.060000   \n",
       "2                       0.000000                  0.000000   \n",
       "3                       2.340000                  0.500000   \n",
       "4                       2.790000                  0.510000   \n",
       "...                          ...                       ...   \n",
       "28103                   0.179173                  0.017707   \n",
       "28104                  51.157546                 51.157546   \n",
       "28105                   0.000000                  0.000000   \n",
       "28106                   0.277072                  0.000000   \n",
       "28107                  76.738000                 76.396072   \n",
       "\n",
       "       Added  Sugar(g) per 100 g  fibre(g) per 100 g  \\\n",
       "0                            0.0            0.000000   \n",
       "1                            0.0            0.000000   \n",
       "2                            0.0            0.000000   \n",
       "3                            0.0            0.000000   \n",
       "4                            0.0            0.000000   \n",
       "...                          ...                 ...   \n",
       "28103                        0.0            0.000000   \n",
       "28104                        0.0            0.000000   \n",
       "28105                        0.0            0.000000   \n",
       "28106                        0.0            0.000000   \n",
       "28107                        0.0            0.023063   \n",
       "\n",
       "       total fat (g) per 100 gms  saturated fat (g) per 100 g  \\\n",
       "0                          81.11                    51.368000   \n",
       "1                          78.30                    45.390000   \n",
       "2                          99.48                    61.924000   \n",
       "3                          28.74                    18.669000   \n",
       "4                          29.68                    18.764000   \n",
       "...                          ...                          ...   \n",
       "28103                       0.00                     0.000000   \n",
       "28104                       0.00                     0.000000   \n",
       "28105                       0.00                     0.000000   \n",
       "28106                       0.00                     0.001745   \n",
       "28107                       0.00                     0.000000   \n",
       "\n",
       "       trans fat (g) _per 100 g  Sodium(mg) per 100 g  iron (mg) per 100 gm  \\\n",
       "0                           0.0            643.000000              0.020000   \n",
       "1                           0.0            583.000000              0.050000   \n",
       "2                           0.0              2.000000              0.000000   \n",
       "3                           0.0           1146.000000              0.310000   \n",
       "4                           0.0            560.000000              0.430000   \n",
       "...                         ...                   ...                   ...   \n",
       "28103                       0.0              4.114663              0.008853   \n",
       "28104                       0.0             55.787729              0.000000   \n",
       "28105                       0.0              4.498168              0.000000   \n",
       "28106                       0.0              3.127376              0.020000   \n",
       "28107                       0.0              2.230625              0.074972   \n",
       "\n",
       "       Cholesterol per 100 mg  Health_Label_High_Cholesterol  \\\n",
       "0                       215.0                              1   \n",
       "1                       225.0                              1   \n",
       "2                       256.0                              1   \n",
       "3                        75.0                              1   \n",
       "4                        94.0                              1   \n",
       "...                       ...                            ...   \n",
       "28103                     0.0                              0   \n",
       "28104                     0.0                              0   \n",
       "28105                     0.0                              0   \n",
       "28106                     0.0                              0   \n",
       "28107                     0.0                              0   \n",
       "\n",
       "       Health_Label_High_sugar  Health_Label_for_normal_person  \\\n",
       "0                            0                               1   \n",
       "1                            0                               1   \n",
       "2                            0                               1   \n",
       "3                            0                               1   \n",
       "4                            0                               1   \n",
       "...                        ...                             ...   \n",
       "28103                        0                               0   \n",
       "28104                        0                               0   \n",
       "28105                        0                               0   \n",
       "28106                        0                               0   \n",
       "28107                        0                               0   \n",
       "\n",
       "       Health_Label_High_fat  \n",
       "0                        1.0  \n",
       "1                        1.0  \n",
       "2                        1.0  \n",
       "3                        1.0  \n",
       "4                        1.0  \n",
       "...                      ...  \n",
       "28103                    0.0  \n",
       "28104                    0.0  \n",
       "28105                    0.0  \n",
       "28106                    0.0  \n",
       "28107                    0.0  \n",
       "\n",
       "[28108 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'Healthy' with 0 and 'Unhealthy' with 1 directly using replace\n",
    "p[['Health_Label_High_fat']] = p[['Health_Label_High_fat']].replace({'Healthy': 0, 'Unhealthy': 1})\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Health_Label_High_fat\n",
       "1.0    14054\n",
       "0.0    14031\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p['Health_Label_High_fat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[2758    0]\n",
      " [   0 2864]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Feature selection/engineering - Assuming all columns except 'Food_name' and 'Health_Label' are features\n",
    "X = p.drop(columns=['Health_Label_for_normal_person'])\n",
    "y = p['Health_Label_for_normal_person']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a classification algorithm (Random Forest Classifier in this case)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=p.iloc[:,:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[2758    0]\n",
      " [   0 2864]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Feature selection/engineering - Assuming all columns except 'Food_name' and 'Health_Label' are features\n",
    "X = d\n",
    "y = p['Health_Label_for_normal_person']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a classification algorithm (Random Forest Classifier in this case)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9996442547136251\n",
      "Confusion Matrix:\n",
      "[[3134    1]\n",
      " [   1 2486]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Feature selection/engineering - Assuming all columns except 'Food_name' and 'Health_Label' are features\n",
    "X =d\n",
    "y = p['Health_Label_High_Cholesterol']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a classification algorithm (Random Forest Classifier in this case)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9957310565635006\n",
      "Confusion Matrix:\n",
      "[[4084   22]\n",
      " [   2 1514]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Feature selection/engineering - Assuming all columns except 'Food_name' and 'Health_Label' are features\n",
    "X = d\n",
    "y = p['Health_Label_High_sugar']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a classification algorithm (Random Forest Classifier in this case)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = p.isna().sum()\n",
    "p=p.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy(kcal)_per 100 g             0\n",
       "Protein(g) per 100 g               0\n",
       "Carbohydrate(g) per 100 g          0\n",
       "total sugar(g) per 100 g           0\n",
       "Added  Sugar(g) per 100 g          0\n",
       "fibre(g) per 100 g                 0\n",
       "total fat (g) per 100 gms          0\n",
       "saturated fat (g) per 100 g        0\n",
       "trans fat (g) _per 100 g           0\n",
       "Sodium(mg) per 100 g               0\n",
       "iron (mg) per 100 gm               0\n",
       "Cholesterol per 100 mg             0\n",
       "Health_Label_High_Cholesterol      0\n",
       "Health_Label_High_sugar            0\n",
       "Health_Label_for_normal_person     0\n",
       "Health_Label_High_fat             23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Predict on the testing set\u001b[39;00m\n\u001b[1;32m     20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:363\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1279\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     )\n\u001b[1;32m   1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1264\u001b[0m     X,\n\u001b[1;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1277\u001b[0m )\n\u001b[0;32m-> 1279\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1281\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1289\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[0;32m-> 1289\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1299\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1046\u001b[0m     )\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1049\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Feature selection/engineering - Assuming all columns except 'Food_name' and 'Health_Label' are features\n",
    "X = d\n",
    "y = p['Health_Label_High_fat']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a classification algorithm (Random Forest Classifier in this case)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5665/3141629961.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p['Health_Label_High_fat'] = label_encoder.fit_transform(p['Health_Label_High_fat'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9761438490297312\n",
      "Confusion Matrix:\n",
      "[[2732   53]\n",
      " [  81 2751]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      2785\n",
      "           1       0.98      0.97      0.98      2832\n",
      "\n",
      "    accuracy                           0.98      5617\n",
      "   macro avg       0.98      0.98      0.98      5617\n",
      "weighted avg       0.98      0.98      0.98      5617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Convert '' to binary labels\n",
    "label_encoder = LabelEncoder()\n",
    "p['Health_Label_High_fat'] = label_encoder.fit_transform(p['Health_Label_High_fat'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = p.drop(columns=['Health_Label_High_fat'])\n",
    "y = p['Health_Label_High_fat']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the testing set\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Classification Report:\\n{class_report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9581627203133345\n",
      "Confusion Matrix:\n",
      "[[3071  106]\n",
      " [ 129 2311]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      3177\n",
      "           1       0.96      0.95      0.95      2440\n",
      "\n",
      "    accuracy                           0.96      5617\n",
      "   macro avg       0.96      0.96      0.96      5617\n",
      "weighted avg       0.96      0.96      0.96      5617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5665/1691026505.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p['Health_Label_High_Cholesterol'] = label_encoder.fit_transform(p['Health_Label_High_Cholesterol'])\n",
      "/home/shubham/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Convert '' to binary labels\n",
    "label_encoder = LabelEncoder()\n",
    "p['Health_Label_High_Cholesterol'] = label_encoder.fit_transform(p['Health_Label_High_Cholesterol'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = p.drop(columns=['Health_Label_High_Cholesterol'])\n",
    "y = p['Health_Label_High_Cholesterol']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the testing set\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Classification Report:\\n{class_report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Energy(kcal)_per 100 g', 'Protein(g) per 100 g',\n",
       "       'Carbohydrate(g) per 100 g', 'total sugar(g) per 100 g',\n",
       "       'Added  Sugar(g) per 100 g', 'fibre(g) per 100 g',\n",
       "       'total fat (g) per 100 gms', 'saturated fat (g) per 100 g',\n",
       "       'trans fat (g) _per 100 g', 'Sodium(mg) per 100 g',\n",
       "       'iron (mg) per 100 gm', 'Cholesterol per 100 mg',\n",
       "       'Health_Label_High_Cholesterol', 'Health_Label_High_sugar',\n",
       "       'Health_Label_for_normal_person', 'Health_Label_High_fat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5665/715532936.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p['Health_Label_High_sugar'] = label_encoder.fit_transform(p['Health_Label_High_sugar'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8926473206337903\n",
      "Confusion Matrix:\n",
      "[[3859  274]\n",
      " [ 329 1155]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      4133\n",
      "           1       0.81      0.78      0.79      1484\n",
      "\n",
      "    accuracy                           0.89      5617\n",
      "   macro avg       0.86      0.86      0.86      5617\n",
      "weighted avg       0.89      0.89      0.89      5617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Convert '' to binary labels\n",
    "label_encoder = LabelEncoder()\n",
    "p['Health_Label_High_sugar'] = label_encoder.fit_transform(p['Health_Label_High_sugar'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = p.drop(columns=['Health_Label_High_sugar'])\n",
    "y = p['Health_Label_High_sugar']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the testing set\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Classification Report:\\n{class_report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9761438490297312\n",
      "Confusion Matrix:\n",
      "[[2732   53]\n",
      " [  81 2751]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      2785\n",
      "           1       0.98      0.97      0.98      2832\n",
      "\n",
      "    accuracy                           0.98      5617\n",
      "   macro avg       0.98      0.98      0.98      5617\n",
      "weighted avg       0.98      0.98      0.98      5617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5665/2149735024.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p['Health_Label_for_normal_person'] = label_encoder.fit_transform(p['Health_Label_for_normal_person'])\n",
      "/home/shubham/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Convert '' to binary labels\n",
    "label_encoder = LabelEncoder()\n",
    "p['Health_Label_for_normal_person'] = label_encoder.fit_transform(p['Health_Label_for_normal_person'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = p.drop(columns=['Health_Label_for_normal_person'])\n",
    "y = p['Health_Label_for_normal_person']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the testing set\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Classification Report:\\n{class_report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5665/1288942800.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p['Health_Label_for_normal_person'] = label_encoder.fit_transform(p['Health_Label_for_normal_person'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.9761438490297312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors: 0.9761438490297312\n",
      "Support Vector Machine: 0.9141890688979882\n",
      "Naive Bayes: 0.9996439380452199\n",
      "Decision Tree: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Convert 'Health_Label_for_normal_person' to binary labels\n",
    "label_encoder = LabelEncoder()\n",
    "p['Health_Label_for_normal_person'] = label_encoder.fit_transform(p['Health_Label_for_normal_person'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = p.drop(columns=[ 'Health_Label_for_normal_person'])\n",
    "y = p['Health_Label_for_normal_person']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.9581627203133345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5665/2584071.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p['Health_Label_High_Cholesterol'] = label_encoder.fit_transform(p['Health_Label_High_Cholesterol'])\n",
      "/home/shubham/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors: 0.9690226099341286\n",
      "Support Vector Machine: 0.9175716574683995\n",
      "Naive Bayes: 0.9414278084386684\n",
      "Decision Tree: 0.9996439380452199\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Convert 'Health_Label_High_Cholesterol' to binary labels\n",
    "label_encoder = LabelEncoder()\n",
    "p['Health_Label_High_Cholesterol'] = label_encoder.fit_transform(p['Health_Label_High_Cholesterol'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = p.drop(columns=[ 'Health_Label_High_Cholesterol'])\n",
    "y = p['Health_Label_High_Cholesterol']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.8926473206337903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5665/2602898905.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p['Health_Label_High_sugar'] = label_encoder.fit_transform(p['Health_Label_High_sugar'])\n",
      "/home/shubham/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors: 0.9886060174470358\n",
      "Support Vector Machine: 0.9556702866298736\n",
      "Naive Bayes: 0.9157913476944989\n",
      "Decision Tree: 0.9937689157913477\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Convert 'Health_Label_High_sugar' to binary labels\n",
    "label_encoder = LabelEncoder()\n",
    "p['Health_Label_High_sugar'] = label_encoder.fit_transform(p['Health_Label_High_sugar'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = p.drop(columns=[ 'Health_Label_High_sugar'])\n",
    "y = p['Health_Label_High_sugar']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5665/4242080452.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p['Health_Label_High_fat'] = label_encoder.fit_transform(p['Health_Label_High_fat'])\n",
      "/home/shubham/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.9761438490297312\n",
      "K-Nearest Neighbors: 0.9761438490297312\n",
      "Support Vector Machine: 0.9141890688979882\n",
      "Naive Bayes: 0.9996439380452199\n",
      "Decision Tree: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Convert 'Health_Label_High_fat' to binary labels\n",
    "label_encoder = LabelEncoder()\n",
    "p['Health_Label_High_fat'] = label_encoder.fit_transform(p['Health_Label_High_fat'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = p.drop(columns=[ 'Health_Label_High_fat'])\n",
    "y = p['Health_Label_High_fat']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Energy(kcal)_per 100 g', 'Protein(g) per 100 g',\n",
       "       'Carbohydrate(g) per 100 g', 'total sugar(g) per 100 g',\n",
       "       'Added  Sugar(g) per 100 g', 'fibre(g) per 100 g',\n",
       "       'total fat (g) per 100 gms', 'saturated fat (g) per 100 g',\n",
       "       'trans fat (g) _per 100 g', 'Sodium(mg) per 100 g',\n",
       "       'iron (mg) per 100 gm', 'Cholesterol per 100 mg',\n",
       "       'Health_Label_High_Cholesterol', 'Health_Label_High_sugar',\n",
       "       'Health_Label_for_normal_person', 'Health_Label_High_fat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.10/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n",
      "2024-05-01 14:40:44.058297: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-01 14:40:44.743889: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-01 14:40:46.437124: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-01 14:40:50.054010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_5665/1386342347.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p['Health_Label_for_normal_person'] = label_encoder.fit_transform(p['Health_Label_for_normal_person'])\n",
      "/home/shubham/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Machine Learning Models:\n",
      "Logistic Regression: 0.9761438490297312\n",
      "K-Nearest Neighbors: 0.9761438490297312\n",
      "Support Vector Machine: 0.9141890688979882\n",
      "Naive Bayes: 0.9996439380452199\n",
      "Decision Tree: 1.0\n",
      "Random Forest: 1.0\n",
      "Gradient Boosting: 1.0\n",
      "AdaBoost: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier# Load the dataset\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "p['Health_Label_for_normal_person'] = label_encoder.fit_transform(p['Health_Label_for_normal_person'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = p.drop(columns=[ 'Health_Label_for_normal_person'])\n",
    "y = p['Health_Label_for_normal_person']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Gaussian Process': GaussianProcessClassifier(),\n",
    "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(),\n",
    "    'HistGradientBoosting': HistGradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate traditional ML classifiers\n",
    "print(\"Traditional Machine Learning Models:\")\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name}: {accuracy}\")\n",
    "\n",
    "# Define deep learning model using TensorFlow/Keras\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nDeep Learning Model:\")\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mLabelEncoder\u001b[49m()\n\u001b[1;32m      2\u001b[0m p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHealth_Label_High_Cholesterol\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHealth_Label_High_Cholesterol\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Define features and target variable\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "p['Health_Label_High_Cholesterol'] = label_encoder.fit_transform(p['Health_Label_High_Cholesterol'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = p.drop(columns=[ 'Health_Label_High_Cholesterol'])\n",
    "y = p['Health_Label_High_Cholesterol']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Gaussian Process': GaussianProcessClassifier(),\n",
    "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(),\n",
    "    'HistGradientBoosting': HistGradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate traditional ML classifiers\n",
    "print(\"Traditional Machine Learning Models:\")\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name}: {accuracy}\")\n",
    "\n",
    "# Define deep learning model using TensorFlow/Keras\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nDeep Learning Model:\")\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
